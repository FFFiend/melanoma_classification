{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYTZa0StybvP",
        "outputId": "11a50f78-a5e0-4ab5-afd3-c9d4c04ee570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "quKShqz2y7FR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "device = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-OLVBs95PNP",
        "outputId": "52ec5d90-5dac-42aa-ae05-94e9b8210346"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dir = \"/content/drive/MyDrive/melanoma_cancer_dataset/train\"\n",
        "test_dir = \"/content/drive/MyDrive/melanoma_cancer_dataset/test\"\n",
        "# Pytorch ImageFolder and DataLoader are way too overpowered.\n",
        "train_data = torchvision.datasets.ImageFolder(train_dir, transform=torchvision.transforms.ToTensor())\n",
        "test_data = torchvision.datasets.ImageFolder(test_dir, transform=torchvision.transforms.ToTensor())\n",
        "len(train_data)\n",
        "#9605 training images\n",
        "len(test_data)\n",
        "#1000 testing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET9RNhln7Jpn",
        "outputId": "2cafa1cd-b43f-4fbc-b29e-d3efa6a7186d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 300, 300])\n",
            "tensor([[[[0.4471, 0.4510, 0.4588,  ..., 0.3176, 0.3059, 0.2980],\n",
            "          [0.4510, 0.4549, 0.4627,  ..., 0.3176, 0.3059, 0.2980],\n",
            "          [0.4627, 0.4627, 0.4667,  ..., 0.3294, 0.3176, 0.3098],\n",
            "          ...,\n",
            "          [0.5490, 0.5529, 0.5569,  ..., 0.3922, 0.3765, 0.3686],\n",
            "          [0.5490, 0.5529, 0.5569,  ..., 0.3843, 0.3686, 0.3608],\n",
            "          [0.5451, 0.5490, 0.5569,  ..., 0.3804, 0.3647, 0.3569]],\n",
            "\n",
            "         [[0.3294, 0.3333, 0.3412,  ..., 0.2471, 0.2353, 0.2275],\n",
            "          [0.3333, 0.3373, 0.3451,  ..., 0.2471, 0.2353, 0.2275],\n",
            "          [0.3451, 0.3451, 0.3490,  ..., 0.2471, 0.2353, 0.2275],\n",
            "          ...,\n",
            "          [0.4392, 0.4431, 0.4471,  ..., 0.3098, 0.3059, 0.2980],\n",
            "          [0.4392, 0.4431, 0.4471,  ..., 0.3020, 0.2980, 0.2902],\n",
            "          [0.4353, 0.4392, 0.4471,  ..., 0.2980, 0.2941, 0.2863]],\n",
            "\n",
            "         [[0.3294, 0.3333, 0.3412,  ..., 0.3020, 0.2902, 0.2824],\n",
            "          [0.3333, 0.3373, 0.3451,  ..., 0.3020, 0.2902, 0.2824],\n",
            "          [0.3451, 0.3451, 0.3490,  ..., 0.3059, 0.2941, 0.2863],\n",
            "          ...,\n",
            "          [0.4863, 0.4902, 0.4941,  ..., 0.3686, 0.3608, 0.3529],\n",
            "          [0.4941, 0.4980, 0.5020,  ..., 0.3608, 0.3529, 0.3451],\n",
            "          [0.4902, 0.4941, 0.5020,  ..., 0.3569, 0.3490, 0.3412]]]]) tensor([1])\n",
            "torch.Size([1, 3, 300, 300])\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
        "print(train_data[0][0].shape)\n",
        "# sanity checking, imagefolder changes tensor shape but thats alright I guess.\n",
        "for x, t in train_loader:\n",
        "    print(x, t)\n",
        "    print(x.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VOB6QLDYzyuR"
      },
      "outputs": [],
      "source": [
        "class MelanomaCNN(nn.Module):\n",
        "    def __init__(self, width=3, normalize_batch=True):\n",
        "        \"\"\"\n",
        "        Init method for the model.\n",
        "        \"\"\"\n",
        "        super(MelanomaCNN, self).__init__()\n",
        "        self.width = width\n",
        "        self.bn = normalize_batch\n",
        "        self.maxpool_layer = nn.MaxPool2d(3,3)\n",
        "        self.maxpool_layer.cuda()\n",
        "        # first conv2d layer\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=self.width,\n",
        "            out_channels=16,\n",
        "            kernel_size=7,\n",
        "        )\n",
        "        self.conv1.cuda()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=16,\n",
        "            out_channels=32,\n",
        "            kernel_size=7\n",
        "        )\n",
        "        self.conv2.cuda()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels=32,\n",
        "            out_channels=64,\n",
        "            kernel_size=3\n",
        "        )\n",
        "        self.conv3.cuda()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=128,\n",
        "            kernel_size=3\n",
        "        )\n",
        "        self.conv4.cuda()\n",
        "        # 3 batch norm channels corresponding to output num channels of each conv\n",
        "        # layer.\n",
        "        if self.bn:\n",
        "          #self.bn1 = nn.BatchNorm2d(self.width)\n",
        "          self.bn2 = nn.BatchNorm2d(32)\n",
        "          self.bn2.cuda()\n",
        "          #self.bn3 = nn.BatchNorm2d(64)\n",
        "          #self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc1 = nn.Linear(512 ,256)\n",
        "        self.fc1.cuda()\n",
        "        self.fc2 = nn.Linear(256,2)\n",
        "        self.fc2.cuda()\n",
        "\n",
        "        # final output should be batch size * 2\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.maxpool_layer(torch.relu(self.conv1(x)))\n",
        "        x.cuda()\n",
        "        #if self.bn:\n",
        "            #x = self.bn1(x)\n",
        "\n",
        "        x = self.maxpool_layer(torch.relu(self.conv2(x)))\n",
        "        x.cuda()\n",
        "\n",
        "        if self.bn:\n",
        "            x = self.bn2(x)\n",
        "            x.cuda()\n",
        "\n",
        "        x = self.maxpool_layer(torch.relu(self.conv3(x)))\n",
        "        x.cuda()\n",
        "\n",
        "        #if self.bn:\n",
        "            #x = self.bn3(x)\n",
        "\n",
        "        x = self.maxpool_layer(torch.relu(self.conv4(x)))\n",
        "        x.cuda()\n",
        "\n",
        "        #if self.bn:\n",
        "          #x = self.bn4(x)\n",
        "\n",
        "        # flatten the image.\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x.cuda()\n",
        "\n",
        "        # might swap relu out for smth else\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x.cuda()\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zbX56yi2zaPS"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, data, device=\"cuda:0\"):\n",
        "    \"\"\"\n",
        "    Accuracy function, self explanatory.\n",
        "    \"\"\"\n",
        "    loader = torch.utils.data.DataLoader(data, batch_size=32)\n",
        "    model.to(device)\n",
        "    model.eval() # annotate model for evaluation (important for batch normalization)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in loader:\n",
        "        labels = labels.to(device)\n",
        "        output = model(imgs.to(device))\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "def train_model(model,\n",
        "                train_data,\n",
        "                valid_data,\n",
        "                batch_size=32,\n",
        "                weight_decay=0.0,\n",
        "                learning_rate=0.075,\n",
        "                num_epochs=10,\n",
        "                plot_every=20,\n",
        "                plot=True,\n",
        "                device=torch.device(\"cuda:0\")):\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "    model = model.to(device) # move model to GPU if applicable\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=learning_rate,\n",
        "                           weight_decay=weight_decay)\n",
        "    # for plotting\n",
        "    iters, train_loss, train_acc, val_acc = [], [], [], []\n",
        "    iter_count = 0 # count the number of iterations that has passed\n",
        "\n",
        "    try:\n",
        "        for epoch in range(num_epochs):\n",
        "            for imgs, labels in iter(train_loader):\n",
        "                if imgs.size()[0] < batch_size:\n",
        "                    continue\n",
        "                labels = labels.to(device)\n",
        "                imgs = imgs.to(device)\n",
        "                model.train()\n",
        "                out = model(imgs)\n",
        "                loss = criterion(out, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                iter_count += 1\n",
        "                if iter_count % plot_every == 0:\n",
        "                    loss = float(loss)\n",
        "                    tacc = get_accuracy(model, train_data, device)\n",
        "                    vacc = get_accuracy(model, valid_data, device)\n",
        "                    print(\"Iter %d; Loss %f; Train Acc %.3f; Val Acc %.3f\" % (iter_count, loss, tacc, vacc))\n",
        "\n",
        "                    iters.append(iter_count)\n",
        "                    train_loss.append(loss)\n",
        "                    train_acc.append(tacc)\n",
        "                    val_acc.append(vacc)\n",
        "    finally:\n",
        "        plt.figure()\n",
        "        plt.plot(iters[:len(train_loss)], train_loss)\n",
        "        plt.title(\"Loss over iterations\")\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(iters[:len(train_acc)], train_acc)\n",
        "        plt.plot(iters[:len(val_acc)], val_acc)\n",
        "        plt.title(\"Accuracy over iterations\")\n",
        "        plt.xlabel(\"Iterations\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend([\"Train\", \"Validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XYaX_LD2_HCH"
      },
      "outputs": [],
      "source": [
        "model = MelanomaCNN()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
